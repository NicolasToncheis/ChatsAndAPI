# Aplicação de Chats e Configurações API

#1) API do Azure OpenAI: Suporte para Chat, Completar, Imagem e Áudio (não visto aqui). Chamada do objeto:
![image](https://github.com/user-attachments/assets/412b77c2-c47d-4469-8efd-d85f36d5fb94)
![image](https://github.com/user-attachments/assets/190d1e25-0df1-4186-b4a1-17d9f945a9ae)
Lembrando que outras variáveis para a sua geração de conteúdo podem ser inseridas, como ID do Modelo, Temperatura, Top-P e Penalidades de Frequência/Presença.

#2) Hands-On: Control Plane: é o que gerecia o endpoint, disponível em todas as operações do Azure OpenAI. Já o Data Plane, é dividido ente o Authoring (mais utilizado para fine-tuning) e o Inference (que será importante para nossa análise). Como foi visto, no próprio exemplo de código dos modelos disponíveis, a Microsoft tem uma preferência por utilizar a autenticação via Microsoft Entra, por ser mais seguro, porém, é possível utilizar uma chamada API. Pode verificar até alguns modelos de prompt com código completo, podendo inserir diferentes temperaturas para comparar diferentes respostas a um mesmo prompt, sendo importante, desde já, ter o cuidado com o gerenciamento das mensagens. É preciso deletar duas, ao gerenciar as mensagens, por causa do par system-user. Para realizar um chat com foco em codificação, existe o Codex para o Azure OpenAI, apesar da opção mais vantajosa ser o ChatGPT. Cuidado: a chamada correta da biblioteca para utilizar os recursos em um código Python é: pip install openai !! Em Implantações é possível ver as métricas de uso do Azure OpenAI, como, por exemplo, o consumo de tokens e os filtros de segurança colocados em cada modelo.

#3) Introdução ao Semantic Kernel: Primeiro, sempre se deve ter cuidado em criar agentes de IA que não tenham uma performance indesejável antes de prosseguir com o a criação de novos (Garbage In, Garbage Out). O Semantic Kernel é o Middleware de IA, que fará essa coordenação dos agentes, integrando a atualização de modelos, com plugins, com seu código próprio e até com Hooks & Filters, interconectando com seu app e outros apps de IA. O Kernel vira o centro de tudo. Na Memory, são usados Vectory Stores, com uma API para buscar rapidamente. Carrega o Kernel -> carrega os serviços -> carrega o Azure OpenAI -> adiciona o plugin. O SK já gerencia as memórias de mensagem pelo usuário, uma ve implementado. Como dica final, é interessante ler por completo o material sobre Semantic Kernel disponível no próprio site da Microsoft (https://learn.microsoft.com/en-us/semantic-kernel/overview/).
